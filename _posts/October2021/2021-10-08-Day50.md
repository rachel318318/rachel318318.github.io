---
layout: post
title: 📔 Daily Report | Day 50
date: 2021-10-08 10:15 +0900
#modified: 2021-07-30 18:49 +0900
description: Day 50
tag:
  - Boostcamp AI
  - Daily Report
  - Object Detection Competition
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# 1. 멘토링 세션

- 지금 중위권이에요
    - 그러면 지금 하고있는 실험 계속할 것
    - 상위권은 tuning 싸움
- detectron2는 너무 high-level,,,
- mmdetection faster RCNN 사용해서 돌려본 결과인데요, loss_rpn_bbox와 loss_bbox 차이나는 이유가 무엇일까요..? NMS 하면서 ground truth와 조금씩 벗어나서 그런걸까요?
    - Faster RCNN loss 값 두개 from 위치를 찾아주는 네트워크, 위치를 제안하는 네트워크 두개 있고 들어가는 bbox가 다를 수 밖에 없다. 최종적 loss는 네개가 더해진 것 (loss_rpn_cls, loss_rpn_bbox, loss_cls, loss_bbox)
- mask head가 있는 모델의 경우, bbox형태로 mask를 넣어서 학습을 진행한다면 성능 개선이 있을까요~ 없을까요~?
  - local minimum에 빠질 수도 있어서 학습이 잘 되지 않을 수도 있다,,, ground truth 아닌 애들도 segmentation해 버릴 수도 있기 때문에 일반적으로 안 좋지는 않을까라는 의견도 있음
- multi scale training을 할 때 보통 원본 사이즈보다 더 큰 size로 학습을 하나요? 작게 학습을 하는 것도 도움이 될까요?
  - 작은 거를 크게 하는 건 좀 애매하다, 원본 사이즈보다 크게 한다는 것은 정보 손실을 각오하고 하는 것 픽셀을 뻥튀기하고 그러는 것 과연 도움이 될까? 
- mAP metric에서 bbox가 많이 생겨도 패널티가 없으면 NMS, soft NMS, WBF 등 쓸 필요가 있는가? 대회에서 NMS 등을 쓰는 이유는 무엇인가?
  - NMS 자체는 confidence score 계산해서 내림차순으로 한 다음에 voting, soft NMS는 같은 클래스 객체가 겹쳐있을 경우 쓰는 것, WBF는 각 꼭짓점의 평균 지점을 잡는 것
  - 우리 대회는 쓰레기들 끼리 겹쳐있는게 많아서 WBF가 의미가 있을까? 데이터마다 다르기 때문에 잘 보고 고를 것
  - 이미지당 객체가 한개가 아닐 수도 있기 때문에 기존의 accuracy를 쓸 수 없음
  - mAP는 precision 기반, 내가 정답이라고 말하는 숫자를 줄이는 것이 precision에 더 유리함
- Precision vs. Recall
  - Precision: 니가 정답이라고 주장하는 것들 중에 진짜 정답이 몇개냐?
  - Recall: 진짜 정답들중에 니가 몇개 맞췄냐?
  - mAP: mean avg precision → 바운딩박스 무조건 많이 쳐두면 precision값 낮아짐 → mAP ~~대가리~~ 박살
- threshold를 낮춰서 성능을 높이는 것보다 threshold가 높은 상태에서 모델 자체의 성능을 올려야한다 (0.5가 디폴트)
- 잘못된 annotation이 있기에 ground truth를 건드려서 다시 학습하는 것도 추천 → 사진 전체가 annotation되어 있다던가,,,
    - 아예 학습할 때 제외시키는 것도 방법
- Random Seed는 꼭! 대회때마다 설정하기! → 나중에 돌려보라고 할 수도 있기 때문에
- Testset 보고 데이터 augmentation 전략 짤 수도 있음
- 지금 넣은 augmentation도 충분한 듯 → testset 하고 비교해서 과연 비슷한지 확인하기
- 같은 모델, 같은 백본이라 해도 mmdetection과 detectron2 각각 돌리면 결과가 다르게 나올 것 → 애초에 random weight로 주어지기 때문에 → 좋은 모델 각각 돌려서 앙상블하는 것도 하나의 방법

# 2. 피어 세션

💡 **공유 사항**

- Detectron2에서 사용하는 Metric입니다: [https://cocodataset.org/#detection-eval](https://cocodataset.org/#detection-eval)
- Albumentations에서 사용할 수 있는 augmentation입니다.
Pixel-level transforms은 object detection에서 전부 사용할 수 있고 Spatial-level transforms에서 bboxes에 체크된 transform이 object detection에서 사용할 수 있는 transform입니다: [https://albumentations.ai/docs/api_reference/full_reference/](https://albumentations.ai/docs/api_reference/full_reference/)
- 대회 관련 고려할 부분 정리해봤어요! 추가적으로 고려할 부분이나 의견 남겨주세요!!: [https://github.com/boostcampaitech2/object-detection-level2-cv-04/discussions/6#discussion-3606717](https://github.com/boostcampaitech2/object-detection-level2-cv-04/discussions/6#discussion-3606717)
- MMDetection에서 모델에 상관없이 'num_classes = 10'을 주는 이유! → MMDetection 2.0 버전 이후부터는 모델에 배경에 대한 클래스 추가 (C + 1)에 대해 고려하지 않아도 되게끔 바뀌었습니다.→ 배경에 대한 label은 제일 마지막 번호로! (쓰레기 데이터에서 배경에 대한 label은 10 / 나머지 쓰레기 객체들에 대한 label은 0~9) [https://mmdetection.readthedocs.io/en/latest/compatibility.html#codebase-conventions](https://mmdetection.readthedocs.io/en/latest/compatibility.html#codebase-conventions)

💡 **Todo**

- 데이터 전처리 >> GT 고치기( 비율 이상한것, 너무 큰것 등등 )
코드로 데이터 검수 자동화 (면적 따져서 bbox 너무 큰 애들.. 심상치 않은 애들) -> 데이터셋이 크지 않아서 outlier 처리가 중요한 요소가 될 것 같음
- 모델은 충분히 돌림 → 1-stage 모델만 돌리고 나머지는 튜닝, 성능 쥐어짜기로 넘어가기
- Detectron2 CosineAnealing 추가하기
- EfficientDet 0번을 전혀 구별하기 못함 → 어떻게 고칠 것인가?
- inference할때 나오는 score threshold (< 0.05 → 0.05보다 작은 것은 무시한다)
    - threshold가 낮으니까 같은 영역에 다른 class로 예측한 box가 좀 보인다
    - 상원님 → efficientdet에서 실험했을 때 threshold를 높였는데 mAP가 더 떨어졌다
- train0 valid0말고 다른 데이터셋 언제쓰지? → 상위권 모델들 선정해서 일요일에 k-fold 진행하자
- Data 다시 EDA해서 버려야할 이미지는 제외하고나 GT 바꾸자
- Annotation 보고 밑에 보이는 기준으로 잘못된 것은 기록해놓고 나중에 같이 보자

[https://stages.ai/competitions/76/discussion/talk/post/649](https://stages.ai/competitions/76/discussion/talk/post/649)

<figure>
<img src="/assets/img/IMG_1274.png">
</figure>

💡 **유의 사항**

- 언제나 `RANDOMSEED=42`로 학습 진행 ~~기적의 숫자~~

# 3. 개인적으로 배운 것/리마인드

🌿 **YOLOv5**

[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)

🌿 **SwinT Detectron2**

[https://github.com/xiaohu2015/SwinT_detectron2](https://github.com/xiaohu2015/SwinT_detectron2)

하지만 계속 에러x1000,,, 포기하고 다음 기회에,,, 흑흑

🌿 **VScode formatting**

`Shift + Option + F` 누르면 코드가 정리가 되는 마법!

🌿 **List installed packages**

`pip install` 터미널에 치면 무슨 패키지가 설치되어있는지 볼 수 있다~


# 4. 앞으로 할 일

✅ Kaggle 뒤적거리면서 참고할만한 내용, 트릭들 모아보기\
▶️ ~~Slack 채널로 학습 경과 메시지 보내는 거 셋업하기~~ wandb에서 해줌\
✅ tmux 사용해보기 -> 팀원들에게도 물어보기\
▶️ shell 공부해보기\
✅ validation.json하고 wandb 적용하고 모델 돌리기\
✅ detectron2에 albumentations 적용하기\
▶️ ~~Cascade R-CNN 모델 돌리기~~ 성능 안좋음\
▶️ Swin 깃헙코드 리포 만들어서 모델 돌리기
