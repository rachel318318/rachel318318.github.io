---
layout: post
title: ✏️ U-stage CV | Image Classification 2
date: 2021-09-08 07:44 +0900
#modified: 2021-07-30 18:49 +0900
description: Computer Vision에 대한 심화 학습
tag:
  - Boostcamp AI
  - U-stage Computer Vision
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# Problems with Deeper Layers

### Going Deeper with Convolutions

* 네트워크를 깊게 쌓을 수록 더 좋은 성능을 보여준다는 것은 VGGNet을 통해서 알 수 있었다
    * Larger receptive fields -> 더 많이 주변을 참조, 신중히 결론
    * More capacity and non-linearity
* 하지만 과연 이게 좋기만 할까?

### Hard to Optimize

* 네트워크가 깊어질수록 Gradient accumulate되면서 gradient가 지나치게 작아지거나 엄청 커질 수 있음 -> 이것을 **gradient vanishing/exploding**이라고 지칭한다
* 또한 계산 복잡도가 올라가면서 좋은 GPU가 필요하게 됨
* Degradation problem도 나타나게 된다

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 1.41.17 PM.png">
<figcaption>Fig 1. Gradient vanishing</figcaption>
</figure>

# CNN Architectures for Image Classification 2

위와 같은 optimization problem을 해결하기 위해 다음과 같은 모델이 개발되었다

### GoogLeNet

##### Inception Module

* 여러개의 filter operations을 동시에 적용해서 channel axis에 따라 concatenate한다
    * 1x1, 3x3, 5x5 convolution fulters & 3x3 pooling operation
* 하지만 계산 복잡도가 엄청 늘어나게 된다
* 그래서 각 operation에 1x1 convolution을 적용해서 채널의 수를 줄인다

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 1.41.42 PM.png" width="450">
<figcaption>Fig 2. GoogLeNet inception module</figcaption>
</figure>

##### 1x1 Convolutions

* 공간 크기는 바뀌지 않고 채널 수 바꿔주기로 쓰인다

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 1.44.14 PM.png">
<figcaption>Fig 3. 1x1 Convolutions</figcaption>
</figure>

##### Overall Architecture

* Stem network: vanilla convolution networks
* 다음으로 inception module들을 쌓는다
* Auxiliary classifiers
* Classifier output (a single FC layer)

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 1.44.33 PM.png">
<figcaption>Fig 4. GoogLeNet overall structure</figcaption>
</figure>

##### Auxiliary Classifier

* Vanishing gradient problem을 해결하기 위해서 쓰인다
* 중간과정에 빼낸 gradient를 주입해서 초반 layers만 학습되는 것을 막아준다
* 학습 때만 사용하고 testing할 때는 제외된다

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.34.04 PM.png" width="400">
<figcaption>Fig 5. Auxiliary classifier from GoogLeNet</figcaption>
</figure>

### ResNet

최초로 100개가 넘는 layer를 접층하면서 더 깊게 쌓을 수록 더 성능이 좋아지는 것을 보여줌

##### Degradation Problem

* 네트워크가 깊어질 수록 정확도는 saturated된다 -> 빨리 degrade된다
* 만일 overfitting이라면 parameter 수가 많은 56-layer의 training 정확도가 더 좋아야한다
* 그래서 이것은 overfitting 문제가 아닌 최적화 문제라는 것을 알 수 있음 (gradient vanishing/exploding)

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 1.51.51 PM.png">
<figcaption>Fig 6. Self-training structure</figcaption>
</figure>

##### Hypothesis

* Plain layer: 레이어를 높게 쌓아서 곧바로 x에서 H(x)까지의 관계를 학습한다고 하면 복잡하다
* Residual block: Residual를 학습 -> H(x)가 복잡할 때 적어도 x를 보존하지 않으려해도 된다
    * Target function: H(x) = F(x) + x
    * Residual function: F(x) = H(x) - x
* Shortcut connection
    * Used to fit a residual mapping instead of directly fitting a desired underlying mapping
    * path의 경우의 수가 생겨 어느 path에 degradation이 발생하더라도 다른 path에서 학습 가능한 찬스를 얻을 수 있다
    * O(2^n)의 경우의 수가 생긴다
    * 실제로 training할 떄 gradient는 가장 짧은 path에서 주로 온다고 한다

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.23.11 PM.png">
<figcaption>Fig 7. Residual block</figcaption>
</figure>

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.23.21 PM.png">
<figcaption>Fig 8. Shortcut connection</figcaption>
</figure>

##### Overall Architecture

* ResNet에 적합한 He initialization
    * 기존의 init으로는 결과값이 매우 커지기 때문
* Stack residual blocks
* 3x3 conv layers로 쌓더라도 param 수가 그렇게 늘지 않고 계산이 비교적 빠름
* Batch norm after every conv layer
* 공간해상도가 반으로 줄고(spatially down-sampling) 채널 수는 두배가 된다
* Single FC layer for output classes

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.23.35 PM.png">
<figcaption>Fig 9. ResNet overall architecture</figcaption>
</figure>

### Beyond ResNet

##### DenseNet

* ResNet에서는 두가지 신호를 합쳐버리지만 DenseNet은 Concat한다
* Channel axis를 따라서 Concat하면서 기존의 신호를 보존한다
* 채널이 늘어나긴 하지만 하위 레이어의 feature를 꺼내써야할 때 유용

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.23.57 PM.png" width="400">
<figcaption>Fig 10. DenseNet</figcaption>
</figure>

##### SENet

* Attention across channels
* Squeeze: 각 채널의 공간정보 없애고 분포(평균정보)를 구함
* Excitation: FC layer에서 가져온 attention weights를 각 채널별로 준다 -> attention score이 채널 별로 생김

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.24.14 PM.png">
<figcaption>Fig 11. SENet</figcaption>
</figure>

##### EfficientNet

* Deep, wide, high resolution network를 적당한 비율로 섞는다
* 각 네트워크마다 saturated되는 지점과 성능 증가폭이 다르기 때문

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.24.43 PM.png">
<figcaption>Fig 12. Deep, wide, high resolution network and EfficientNet</figcaption>
</figure>

##### Deformable Convolution

* 자동차나 물건은 대부분 모양이 정해져있지만 동물 등은 부위마다 상대적 위치가 바뀐다
* 2D spatial offset으로 불규칙한 grid sampling을 만든다
* 사각형이 아닌 deformed된 receptive field가 생성된 것을 볼 수 있다

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.24.53 PM.png">
<figcaption>Fig 13. Deformable convolution</figcaption>
</figure>

# Summary of Image Classification

<figure>
<img src="/assets/img/Screen Shot 2021-09-09 at 2.25.05 PM.png" width="400">
<figcaption>Fig 14. Image classification model comparison</figcaption>
</figure>

* GoogLeNet이 가장 효율적인 모델이다
    * 하지만 Auxiliary classifiers 등 다루기가 좀 어렵다
* 그래서 주로 VGGNet, ResNet을 backbone model로 이용한다
    * 간단한 네트워크 구조, 쌓기 쉬움