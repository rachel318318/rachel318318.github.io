---
layout: post
title: ✏️ U-stage | DL Basics in CNN
date: 2021-08-11 07:44 +0900
#modified: 2021-07-30 18:49 +0900
description: 머신러닝 수학의 기초가 되는 개념들을 훑어보는 시간
tag:
  - Boostcamp AI
  - U-stage
  - DL Basics
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# Convolutional Neural Networks

### Convolution

* Apply a set of weight, a filter(kernel), to an image and to extract local feature
    * This outputs a feature map
* Use multiple filters to extract different features
* Spatially share parameters of each filter

<figure>
<img src="/assets/img/Screen Shot 2021-08-11 at 9.39.48 PM.png" alt="convolution">
<figcaption>Fig 1. Convolution example</figcaption>
</figure>

### Pooling

* Also called downsampling
* Reduce dimensionality and preserve spacial invariance

<figure>
<img src="/assets/img/Screen Shot 2021-08-11 at 9.48.32 PM.png" alt="pooling">
<figcaption>Fig 2. Max pooling example</figcaption>
</figure>

### CNN structure

* CNN consists of convolution layer, pooling layer, and fully connected layer
    * Convolution and pooling layers: feature extraction
    * Fully connected layer: decision making (e.g. classification)

<figure>
<img src="/assets/img/Screen Shot 2021-08-11 at 9.51.47 PM.png" alt="pooling">
<figcaption>Fig 3. CNN structure for classification</figcaption>
</figure>

1. Learn features in input image through convolution
2. Introduce non-linearity through activation function
3. Reduce dimensionality and preserve spacial invariance with pooling
4. Above precedures output high-level features of input
5. Fully connected layer uses these features to classify input image
6. Express output as probability of image belonging to a particular class

### Stride and Padding

* Stride decides how many pixels to move
* Padding decides how many extra space to add on the edge of the input

<figure>
<img src="/assets/img/IMG_1255.jpg" alt="stride and padding">
<figcaption>Fig 4. Stride and padding with different values</figcaption>
</figure>

### Convolution Arithmetic

* How to calculate number of parameters?

$$W\:of\:kernel\:\times\:H\:of\:kernel\:\times\:C\:of\:input\:\times\:C\:of\:output$$

(W: width, H: height, C: channels (or depth))

* For fully connected layers or dense layers...

$$D\:of\:input\:\times\:D\:of\:output$$

(D: Dimension)

<figure>
<img src="/assets/img/IMG_1256.jpg" alt="num of parameters">
<figcaption>Fig 5. Number of parameters in each layer</figcaption>
</figure>

🎈 Calculate your own to verify!

### 1x1 Convolution

* Dimension reduction
* To reduce the number of parameters while increasing the depth

<figure>
<img src="/assets/img/IMG_1257.jpg" alt="1x1 Convolution" width="400">
<figcaption>Fig 5. 1x1 Convolution</figcaption>
</figure>

💁‍♀ Please check out <a href="https://www.youtube.com/watch?v=AjtX1N_VT9E" target="_blank">this video</a> to further understand about CNN!