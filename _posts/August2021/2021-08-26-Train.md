---
layout: post
title: 💭 Image Class Comp | Training & Inference
date: 2021-08-26 07:44 +0900
#modified: 2021-07-30 18:49 +0900
description: 이미지 분류 대회를 위한 모델을 만드는 과정
tag:
  - Boostcamp AI
  - P-stage
  - Image Classification Competition
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# Key Concepts for Training

### Loss

<figure>
<img src="/assets/img/IMG_1270.jpg" alt="back propagation">
<figcaption>Fig 1. 오류 역전파</figcaption>
</figure>

* Loss 함수 = Cost 함수 = Error 함수
* Loss도 PyTorch에서 nn.Module의 Family이다
* `loss.backward()`가 실행되면 모델의 파라미터의 grad값이 업데이트 된다
    * `required_grad`가 `True`인 값만

* 심화된 Loss
    * Focal Loss: Class imbalance 문제가 있는 경우, 맞춘 확률이 높은 Class는 조금의 loss를, 맞춘 확률이 낮은 class는 loss를 훨씬 높게 부여
    * Label Smoothing Loss: Class target label을 onehot 표현([1,0,0...])보다는 조금 soft하게 표현해서 일반화 성능을 높임([0.9,0.25,0.25...])

### Optimizer

* 어느 방향으로, 얼마나 크게 파라미터 값을 조정할지?
    * [Optimization]({% post_url /August2021/2021-08-10-Opt %}) 포스트 참고

* LR scheduler
    * Learning rate를 동적으로 조절할 수 없을까?
    * `StepLR`: 특정 Step마다 LR 감소
    * `CosineAnnealingLR`: Cosine 함수 형태처럼 LR을 급격히 변경
    * `ReduceLROnPlateau`: 더 이상 성능 향상이 없을 때 LR 감소

```py
# StepLR
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)

# CosineAnnealingLR
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)

# ReduceLROnPlateau
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, T_max=10, eta_min=0)
```

### Metric

학습된 모델을 객관적으로 평가할 수 있는 지표가 필요

**Classification**: Accuracy, F1-score, precision, recall, ROC & AUC

🎈 데이터 상태에 따라 적절한 Metric을 선택해야한다\
ex) Class 별로 적절히 분포 -> Accuracy, 좋지 않으면 -> F1 score

**Regression**: MAE, MSE

**Ranking**: MRR, NDCG, MAP

# Training & Inference Process

### Training

<figure>
<img src="/assets/img/IMG_1271.jpg" alt="training code" width="450">
<figcaption>Fig 2. 모델 Training code 예시</figcaption>
</figure>

* `model.train()`으로 선언을 먼저 해준다
* `optimizer.zero_grad()`
    * `optimizer`는 미리 따로 생성시킨다
    * 매 epoch마다 grad를 초기화시켜준다
* loss = criterion(outputs, labels)
    * 보통 `loss.py`를 만들어 그곳에 criterion class를 선언해준다
    * 무슨 loss function을 쓸지는 마음대로
* `loss.backward`: 역전파로 모델 학습
* `optimizer.step()`: `grad`를 업데이트 시킨다

### Inference

<figure>
<img src="/assets/img/IMG_1272.jpg" alt="inference code" width="525">
<figcaption>Fig 3. Inference code 예시</figcaption>
</figure>

* `model.eval()`으로 테스팅 시작을 선언해준다
* `with torch.no_grad()`: gradient 계산을 해제한다
* validation 확인: 추론 과정에서 validation set으로 바꿔주기만 하면 된다
* checkpoint: `torch.save(model, path)` or `torch.save(model.state_dict(), path)`

<figure>
<img src="/assets/img/IMG_1273.jpg" alt="training code">
<figcaption>Fig 4. torch.save 예시</figcaption>
</figure>