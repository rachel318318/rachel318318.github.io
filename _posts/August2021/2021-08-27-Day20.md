---
layout: post
title: 📔 Daily Report | Day 20
date: 2021-08-27 10:15 +0900
#modified: 2021-07-30 18:49 +0900
description: Day 20
tag:
  - Boostcamp AI
  - Daily Report
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# 1. 수업 노트

### Ensemble

* 서로 다른 여러 학습 모델 사용
* Stratified K-fold cross validation
    * 가능한 경우를 모두 고려 + split시에 class 분포까지 고려
    * k값은 5가 일반적(너무 적으면 학습데이터가 줄고 많으면 많은 시간이 소요됨)
* TTA (Test Time Augmentation)
    * Test dataset에 노이즈를 섞는 것
* 앙상블 효과는 있지만 효율성을 따지는 현업에서는 기피한다

### Hyperparameter Optimization

* Hidden Layer 갯수, Learning rate, Loss 파라미터, Dropout, Batch size, Optimizer parameter, regularization, k-fold...
* 파라미터를 바꿀때마다 모델을 다시 돌려야하니 효율성이 떨어진다
* Optuna 활용

### Training Visualization

* Tensorboard
* Weight and Bias (wandb)

# 2. 피어 세션

### 이미지 분류 대회에 대해서 토론

💡 클래스를 3개로 나눠서 학습하는 과정에서 마스크 유무는 잘 구별해냈지만 나이와 성별구분에서 성능이 매우 떨어진다는 것을 발견했다. 데이터 레이블링이 잘못된 것인지 모델의 구조가 잘못된 것인지 아직 파악을 못했다.

💡 어제 얘기해둔 것처럼 hyperparameter를 조금 수정했더니 성능이 60%까지 올라갔다(클래스는 18개). 아무래도 더 많은 실험을 강행해야할 것 같다.

💡 피어님이 transforms 대신 albumentation을 활용할 수 있도록 코드를 추가해주셨다. 돌려보니 성능차이는 별로 보이지 않고 오히려 학습속도가 더 빨라졌다는 것이 밝혀졌다.

💡 또 다른 피어님이 tensorboard를 추가해주셨다. 우리의 모델이 학습할때마다 데이터를 출력해 학습 과정을 손쉽게 볼 수 있게 되었다.

💡 앞으로 내가 해야할 일은 클래스 18개를 가지고 이것저것 실험을 해보는 일인 것 같다. focal loss도 적용해보고 싶고 다른 hyperparameter들을 더 바꿔보고 싶다. 또한 마이너하지만 결과값 또한 호율적으로 저장할 수 있도록 만들고 싶다.

# 3. 오늘 마치며...

Hyperparameter를 바꾸니 정확도가 금세 올라간 것을 보고 사실 좀 놀랬다. 사실상 근거?없이 바꾼거라서 왜 이렇게 나온 건지는 아직 이해가 잘 되지 않았지만 원래 이렇게 실험을 하는 거겠지...? 빨리 이것저것 실험해보고 싶다 오호호