---
layout: post
title: 💭 Image Class Comp | Model
date: 2021-08-25 07:44 +0900
#modified: 2021-07-30 18:49 +0900
description: 이미지 분류 대회를 위한 모델을 만드는 과정
tag:
  - Boostcamp AI
  - P-stage
  - Image Classification Competition
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# Model with PyTorch

### PyTorch

* Low-level, Pythonic, Flexibility
* PyTorch 모델의 모든 레이어는 nn.Module 클래스를 따른다

```py
import torch.nn as nn
import torch.nn.functional as F

class MyModel(nn.Module):
    def __init__(self):
        super.__init__()
        self.conv1 = nn.Conv2d(1,20,5)
        self.conv2 = nn.Conv2d(20,20,5)
    
    def forward(self,x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
```
* __init__에서는 또다른 nn.Modules을 정의한다

```py
a = MyModel()
print(a)

>>> MyModel(
    (conv1): Conv2d(1,20,kernel_size=(5,5),stride=(1,1))
    (conv2): Conv2d(20,20,kernel_size=(5,5),stride=(1,1)
)

print(list(a.modules()))

>>> [MyModel(
    (conv1): Conv2d(1,20,kernel_size=(5,5),stride=(1,1))
    (conv2): Conv2d(20,20,kernel_size=(5,5),stride=(1,1)
),
Conv2d(3,20,kernel_size(5,5),stride=(1,1)),
Conv2d(20,20,kernel_size=(5,5),stride=(1,1))]
```
* forward에서는 그 모델(모듈)이 호출 되었을 때 실행되는 함수이다
* 모든 nn.Module은 forward() 함수를 가진다
* 내가 정의한 모델의 forward()를 실행한 것으로 그 모델의 정의된 모듈 각각의 forward()가 실행된다

```py
x = torch.rand((1,3,256,256))
y = a(x) # a.forward(x)
y.shape

>>> torch.size([1,20,248,248])
```
##### Parameters
* weight, bias
* `a.state_dict()`: Dict type, 어느 모듈의 파라미터인지 확인 가능
* `list(a.parameters())`: 파라미터(Tensor type)들의 리스트
* 각 모델 파라미터들은 `data`, `grad`, `required_grad` 변수 등을 가지고 있다
    * `required_grad`를 `False`로 지정하면 `grad` 업데이트를 하지 않는다
    * 곧, 모델이 학습하지 않는다

# Pretrained Model

### Background

* 매번 수많은 이미지를 학습시키는 것은 까다롭고 비효율적
* 좋음 품질, 대용량의 데이터로 미리 학습한 모델을 내 목적에 맞게 다듬어서 사용 가능하다
* `torchvision.models` 활용하라

```py
import torchvision.models as models

resnet18 = models.resnet18(pretrained=True)
alexnet = models.alexnet(pretrained=True)
```

### Transfer Learning

* 내 데이터가 가져온 모델과의 유사성을 고려해야한다
* Pretraining 할 때 설정했던 문제와 현재의 문재 비교
* 문제를 해결하기 위한 학습 데이터가 충분하다면...

<figure>
<img src="/assets/img/IMG_1269.jpg" alt="transfer learning">
<figcaption>Fig 1. Transfer learning case by case</figcaption>
</figure>

* Pretrain할때 사용된 데이터가 우리의 목적에 맞다면 모델의 파라미터를 freeze시켜도 된다
* 만일 목적이랑 다르다면 pretrained된 파라미터 위로 더 학습시킨다
* 만약 학습 데이터가 충분하지 않다면 유사성이 높을 때만 모델을 사용할 수 있다