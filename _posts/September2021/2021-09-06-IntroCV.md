---
layout: post
title: âœï¸ U-stage CV | Intro to CV & Image Classification
date: 2021-09-06 07:44 +0900
#modified: 2021-07-30 18:49 +0900
description: Computer Visionì— ëŒ€í•œ ì‹¬í™” í•™ìŠµ
tag:
  - Boostcamp AI
  - U-stage Computer Vision
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# Conputer Vision

### Couse Overview

##### Artificial Intelligence
* ë¨¼ì € AIì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì
    * ì‚¬ê³ ë¥¼ í†µí•´ ì¸ê³¼ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒ, ì†Œë¦¬, ì§€ê°ëŠ¥ë ¥, understanding ëª¨ë‘ ì§€ëŠ¥ì— í¬í•¨
    * ì¸ê³µì§€ëŠ¥ì˜ referenceëŠ” ì‚¬ëŒì´ë¯€ë¡œ ì‚¬ëŒì„ ì—°êµ¬í•´ë³´ì
* ìœ ì•„ê¸° ì‹œì ˆì— ìš°ë¦¬ëŠ” ì„¸ìƒê³¼ interactionì„ í•˜ëŠ” ë°©ë²•ì„ ë°°ìš´ë‹¤
    * ì˜¤ê°ì„ í™œìš©í•´ì„œ ì§€ê°ëŠ¥ë ¥ì„ ë°œë‹¬ì‹œí‚¨ë‹¤
    * ì§€ê°ëŠ¥ë ¥ìœ¼ë¡œ ì¸ê³¼ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì‚¬ê³ ëŠ¥ë ¥ì„ í‚¤ìš´ë‹¤
* ìœ„ ë…¼ë¦¬ë¥¼ ê¸°ê³„ì— ì ìš©ì‹œì¼œë³´ì
    * ì§€ê°ëŠ¥ë ¥ì´ ì œê³µí•˜ëŠ” ê²ƒ -> (inputê³¼ output) data
    * ì˜¤ê°ì—ì„œ ë” ë‚˜ì•„ê°€ í‘œì •, ë§íˆ¬, ì‹ ì²´ì  ìƒí˜¸ì‘ìš©, ì‚¬íšŒì  ê¸°ì¤€ ë“± ë³µí•©ì ì¸ ê°ê°ì„ ì´ìš©í•˜ì—¬ inputê³¼ output dataë¥¼ ì œê³µí•œë‹¤
    * ì•„ë¬´íŠ¼ ê¸°ê³„ë¡œì„œ **ì§€ê°ëŠ¥ë ¥ í™•ë¦½ì´ í•„ìˆ˜**ì´ë‹¤
* ì‹œê°ì´ ê°€ì¥ ë§ì€ ì •ë³´ë¥¼ ì²˜ë¦¬í•œë‹¤ê³  í•œë‹¤ (75% of incoming information)

##### Computer Vision

<figure>
<img src="/assets/img/Screen Shot 2021-09-06 at 9.00.40 PM.png" alt="human vision steps">
<figcaption>Fig 1. ìš°ë¦¬ê°€ ì‚¬ë¬¼ì„ ë³´ëŠ” ê³¼ì •</figcaption>
</figure>

<figure>
<img src="/assets/img/Screen Shot 2021-09-06 at 9.00.48 PM.png" alt="computer vision steps">
<figcaption>Fig 2. ì»´í“¨í„°ê°€ ì‚¬ë¬¼ì„ ë³´ëŠ” ê³¼ì •</figcaption>
</figure>

- ì»´í“¨í„° ë¹„ì „ ì§€ê°ëŠ¥ë ¥ì˜ ì¢…ë¥˜ëŠ” ë‹¤ì–‘í•˜ë‹¤
    - Color perception
    - Motion perception
    - 3D perception
    - Semantic-level perception
    - Social perception (emotion perception)
    - Visuomotor perception, etc.
- ê·¸ëŸ¬ë‚˜ ì»´í“¨í„° ë¹„ì „ì˜ í•µì‹¬ì€ **ì‚¬ëŒì˜ ì‹œê° ëŠ¥ë ¥ì„ ì´í•´í•˜ê³  ì–´ë–¤ì‹ìœ¼ë¡œ êµ¬í˜„í• ì§€ ì—°êµ¬í•˜ëŠ” ê²ƒ**
- ì‚¬ëŒì˜ ì‹œê° ìì²´ê°€ ì‚¬ì‹¤ìƒ **ë¶ˆì™„ì „**í•˜ë‹¤
    - ì•„ë˜ì˜ ì‚¬ì§„ì„ ì˜ˆë¡œ ìš°ë¦¬ëŠ” ë˜‘ë°”ë¡œ ì„œìˆëŠ” ì‚¬ëŒë§Œ ë´ì™”ê¸°ì— ì‹œê° ê¸°ëŠ¥ì´ biasedë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤
    - ì´ëŸ¬í•œ ë¶ˆì™„ì „ì„±ì„ ë³´ì™„í•˜ëŠ” ê²ƒì´ ì»´í“¨í„° ë¹„ì „ì˜ ë˜ë‹¤ë¥¸ í•µì‹¬

<figure>
<img src="/assets/img/Screen Shot 2021-09-06 at 9.21.05 PM.png" alt="human vision imperfection">
<figcaption>Fig 3. Optical Illusion</figcaption>
</figure>

- Machine Learningì—ì„œì˜ Computer Vision
    - ì „ë¬¸ê°€ê°€ ì§ì ‘ ë°ì´í„° ì¶”ì¶œ, íŠ¹ì§•í™”ì— ê°œì…í•´ì„œ ë°©ë²•ë¡ ì„ ì„¤ê³„í–ˆë‹¤
    - ê°„ë‹¨í•œ ëª¨ë¸ í™œìš©
- ê·¸ì— ë°˜í•´ Deep Learningì—ì„œëŠ” gradient descent ë“±ê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ **ì§ì ‘ ê¸°ê³„ê°€ íŠ¹ì§• ì¶”ì¶œë²•ê³¼ íŒë³„ë²•ì„ ì‚¬ìš©**í•œë‹¤
    - Biasê°€ ë‚®ì•„ì„œ ì‚¬ëŒë³´ë‹¤ ê²°ê³¼ê°€ ë‚«ë‹¤!

<figure>
<img src="/assets/img/Screen Shot 2021-09-06 at 9.23.30 PM.png" alt="machine learning"></figure>

<figure>
<img src="/assets/img/Screen Shot 2021-09-06 at 9.23.41 PM.png" alt="deep learning">
<figcaption>Fig 4. Machine Learningê³¼ Deep Learningì˜ ì°¨ì´</figcaption>
</figure>

# Classification

### Classifier

<figure>
<img src="/assets/img/Screen Shot 2021-09-06 at 9.36.08 PM.png" alt="deep learning" width="550">
<figcaption>Fig 5. Classifier example</figcaption>
</figure>

- ë§Œì¼ ìš°ë¦¬ê°€ ì„¸ìƒ ëª¨ë“  ë°ì´í„°ë¥¼ ê°–ê³  ìˆë‹¤ë©´?
    - k Nearest Neighbors (k-NN)ì„ í†µí•´ ë¶„ë¥˜ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆë‹¤

ğŸˆ k Nearest Neighborsë€?\
Query datapointì˜ ì£¼ë³€ ë°ì´í„°ë“¤ì„ ì°¾ê³  ê·¸ ë°ì´í„°ë“¤ì´ ê°–ë˜ Label ì •ë³´ë“¤ì„ ê°€ì ¸ì™€ì„œ ë¶„ë¥˜í•˜ëŠ” ê²ƒ! (e.g. ì£¼ë³€ì— ë¹¨ê°•ì´ ë§ìœ¼ë‹ˆê¹Œ ì´ê±´ ë¹¨ê°•ì¸ê°€ ë³´ë‹¤~)

<br>
- ê·¸ë ‡ê²Œ ë˜ë©´ ê·¸ì € ê²€ìƒ‰í•´ì„œ ë¹„ìŠ·í•œ ê²ƒì„ ì°¾ì„ ìˆ˜ ìˆê²Œ ëœë‹¤
- í•˜ì§€ë§Œ ì„¸ìƒì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì§ˆ ìˆ˜ë„ ì—†ê³  ë°ì´í„° ì–‘ì— ë”°ë¼ì„œ ë³µì¡ë„ë„ ì˜¬ë¼ê°€ë‹ˆ ë¹„íš¨ìœ¨ì ì´ë‹¤
- ê·¸ë˜ì„œ ë°ì´í„°ë¥¼ ì••ì¶•ì‹œì¼œì„œ Neural Networksì— Parameterë“¤ì„ ë…¹ì—¬ ë„£ëŠ” ê²ƒì´ CNNì˜ í•µì‹¬

### Convolutional Neaural Networks (CNN)

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 2.14.57 PM.png">
<figcaption>Fig 6. A simple perceptron model</figcaption>
</figure>

- CNN ì¤‘ ê°€ì¥ ê°„ë‹¨í•œ ëª¨ë¸ì„ ë³´ì
- Perceptron that takes every pixel of an image as input (Fully-connected layer)
- ê° pixelì— ì„œë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¡œ weighted sum, ì¦‰ ë‚´ì ì„ í•˜ê³ 
- Acfivation functionì„ ì ìš©í•´ì„œ ë¶„ë¥˜ ìŠ¤ì½”ì–´ë¡œ ì¶œë ¥

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 2.34.59 PM.png">
<figcaption>Fig 7. Visualization of single fully connected layer networks</figcaption>
</figure>

- Weight matrixë¥¼ ì˜ìƒêµ¬ì¡°ì— ë§ì¶°ì„œ reshapeí•œë‹¤
- FCLë¥¼ ì…ë ¥ ì˜ìƒê³¼ ë™ì¼í•œ templateì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤
- ì´ templateê³¼ì˜ ë‚´ì ì„ í†µí•´ ê° í´ë˜ìŠ¤ì˜ ìŠ¤ì½”ì–´ë¥¼ ë½‘ì•„ ë¹„êµí•œë‹¤
- Weight matrixë¥¼ ì´ë¯¸ì§€í™” ì‹œí‚¤ë©´ ê·¸ í´ë˜ìŠ¤ì˜ í‰ê·  ì´ë¯¸ì§€ê°€ ë‚˜ì˜¨ë‹¤
- ë‹¨ì ìœ¼ë¡œëŠ” layerê°€ ë‹¨ìˆœí•´ì„œ í‰ê· ì´ë¯¸ì§€ ì™¸ì—ëŠ” í‘œí˜„ì´ ì•ˆëœë‹¤

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 2.40.13 PM.png" width="500">
<figcaption>Fig 8. A prolbem with single fully connected layer networks</figcaption>
</figure>

- ì ìš© ì‹œì  ì¦‰, Test time applicationì—ì„œì˜ ë¬¸ì œ
- ë§Œì•½ ë§ì˜ ì´ë¯¸ì§€ ì¤‘ ì¼ë¶€ë¶„ë§Œ ë‚˜ì˜¤ëŠ” ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ë©´ í•™ìŠµ ë•Œ ë³¸ ì ì´ ì—†ê¸°ì— ì˜ëª»ëœ ê²°ë¡ ì„ ë‚´ë¦¼

### Locally Connected Neural Networks

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 3.07.24 PM.png">
<figcaption>Fig 9. CNNs are locally connected neural networks</figcaption>
</figure>

- ì›ë˜ FCNëŠ” í•˜ë‚˜ì˜ íŠ¹ì§•ì„ ë½‘ê¸° ìœ„í•´ì„œ ëª¨ë“  í™ì…€ë“¤ì„ ê³ ë ¤í•œë‹¤
    - pixelë§ˆë‹¤ weightê°€ ìˆê¸° ë•Œë¬¸ì— parameter ìˆ˜ê°€ ê¸‰ê²©íˆ ì¦ê°€í•œë‹¤
- ë°˜ë©´ LCNì€ ì˜ìƒì˜ ê³µê°„ì˜ ìŠµì„±ì„ ì´í•´í•´ì„œ êµ­ë¶€ì ì¸ ì˜ì—­ë“¤ì˜ connectionì„ ê³ ë ¤í•œë‹¤
    - filter ì´ì™¸ì˜ ì˜ì—­ì—ëŠ” weightê°€ í•„ìš”ì—†ìœ¼ë‹ˆ parameter ìˆ˜ê°€ ì¤„ì–´ë“ ë‹¤
- ì˜ìƒ ì—¬ëŸ¬êµ°ë°ì—ì„œ ë¹„ìŠ·í•œ íŠ¹ì§•ì´ ìˆì„ ìˆ˜ ìˆê¸°ì— ì „ ì˜ì—­ì— connectionì„ ê³µìœ í•˜ë©´ì„œ í•„í„°ê°€ ìˆœíšŒí•˜ë©´ì„œ featureë¥¼ ë½‘ëŠ”ë‹¤ -> sliding window ê¸°ë²•
- Hidden layerì˜ activation nodeë¥¼ feature map í˜•íƒœë¡œ ì”ëœ© ë½‘ëŠ”ë‹¤
- Parameterë¥¼ ì˜ìƒ ì „ì²´ì— ì¬í™œìš©í•  ìˆ˜ ìˆê³  ë” ì ì€ Parameter ìˆ˜ë¡œ íš¨ê³¼ì ì¸ íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ìˆê²Œ ëœë‹¤, ì¦‰, Overfittingë„ ë°©ì§€ë¥¼ í•´ì¤€ë‹¤
- ì¦‰, LCNìœ¼ë¡œ ì–´ë– í•œ íŠ¹ì§•ì˜ ìƒëŒ€ì  ìœ„ì¹˜ê°€ ë°”ë€Œë”ë¼ë„ ê·¸ íŠ¹ì§•ì´ ì ì ˆí•˜ê²Œ ì˜ ë½‘íˆê²Œ ëœë‹¤

# CNN Architectures for Image Classification 1

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 3.10.22 PM.png">
<figcaption>Fig 9. CNNs are locally connected neural networks</figcaption>
</figure>

### LeNet-5

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 3.18.49 PM.png">
<figcaption>Fig 10. LeNet-5</figcaption>
</figure>

- 1988ë…„ ì œì¼ ì‹¬í”Œí•œ CNN ì•„í‚¤í…ì²˜ by ì–€ ë¦¬ì¿¤ (Yann Lecun)
    - Overall architecture: Conv - Pool - Conv - Pool - FC - Fc
    - Convolution: 5x5 filters with stride 1
    - Pooling: 2x2 max pooling with stride 2
- í•œê¸€ì ë‹¨ìœ„ ì¸ì‹, ìš°í¸ ë²ˆí˜¸ ì¸ì‹ì— í¬ê²Œ ì„±ê³µí•´ì„œ ìš°í¸ ìš´ì†¡ì— í° ê¸°ì—¬ë¥¼ í–ˆë‹¤

### AlexNet

- LeNet-5ê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ...
    - ë” í¬ë‹¤ (7 hidden layers, 605k neurons, 60M parameters)
    - ImageNet (large amount of data, 12M)ìœ¼ë¡œ í›ˆë ¨
    - ReLUì™€ dropout ê¸°ë²•ì„ ì‚¬ìš©í–ˆë‹¤

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 3.21.09 PM.png">
<figcaption>Fig 11. AlexNet</figcaption>
</figure>

- Ovreall architecture
    - Conv - Pool - LRN - Conv - Pool - LRN - Conv - Conv - Conv - Pool - FC - FC - FC
    - GPU ë©”ëª¨ë¦¬ê°€ ëª¨ìë¼ 2ê°œë¡œ ë‚˜ë‰œë‹¤
    - Activation mapì´ crossí•˜ëŠ”ë° GPUì— ëª¨ë“  ë¶€ë¶„ì—ì„œ cross communicationì´ ì¼ì–´ë‚˜ë©´ ëŠë ¤ì§€ê¸° ë•Œë¬¸ì— ì¼ë¶€ì—ì„œë§Œ êµí™˜í•œë‹¤

ğŸˆ LRNì´ë€? ì¼ì¢…ì˜ Normalization, Normalizationì€ activation functionì— ì…ë ¥ë˜ê¸° ì „ì— ì ìš©í•¨ìœ¼ë¡œì„œ ê°’ì´ extremeí•´ì§€ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤

> Normalization has become important for deep neural networks that compensate for the unbounded nature of certain activation functions such as ReLU, ELU, etc. With these activation functions, the output layers are not constrained within a bounded range (such as [-1,1] for tanh), rather they can grow as high as the training allows it. To limit the unbounded activation from increasing the output layer values, normalization is used just before the activation function.

ì°¸ê³ : <a href="https://towardsdatascience.com/difference-between-local-response-normalization-and-batch-normalization-272308c034ac" target="_blank">Local Response Normalization</a> / <a href="https://www.thoughtco.com/lateral-inhibition-4687368" target="_blank">Lateral Inhibition</a>

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 4.07.36 PM.png">
<figcaption>Fig 12. AlexNet êµ¬í˜„ ì˜ˆì‹œ (LRNì€ ì œì™¸)</figcaption>
</figure>

- ë§ˆì§€ë§‰ max poolingëœ 2D activation mapì´ Linear layerë¡œ ê°€ê¸°ìœ„í•´ì„œëŠ” íŠ¹ë³„í•œ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤
- ë°”ë¡œ Tensorë¥¼ Vectorë¡œ ë°”ê¿”ì¤˜ì•¼í•˜ëŠ” ì‘ì—…!
- Average pooling: ê³µê°„ ì •ë³´ë¥¼ ì••ì¶•í•˜ì—¬ ê¸´ ì±„ë„ì¶•ì˜ ì •ë³´ë§Œ ë‚¨ê²¨ë‘ 
- Flattening: Activation mapì„ ì–´ë– í•œ ìˆœì„œë¡œ ë‚˜ì—´í•´ì„œ ë²¡í„° ëª¨ì–‘ìœ¼ë¡œ ë§Œë“¤ê³  ìŒ“ì•„ì¤Œ
- ë‘ ê°œì˜ ì°¨ì´ëŠ” dimension ì°¨ì´ë§Œ ìˆì„ ë¿ ë²¡í„°í™” ì‹œì¼œì£¼ëŠ” ê²ƒì€ ê°™ë‹¤

##### Deprecated Components

- LRN: ìš”ì¦˜ì€ Batch normalizationì„ ë” ë§ì´ ì‚¬ìš©í•œë‹¤
- 11x11 convolution filter: ìš”ì¦˜ì€ ì´ë ‡ê²Œ í° filter sizeë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

### Receptive Field in CNN

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 4.27.01 PM.png">
<figcaption>Fig 13. Receptive field in CNN</figcaption>
</figure>

- í•œ output ê°’ì„ ì •í•˜ê¸° ìœ„í•´ input spaceì—ì„œ ì–´ëŠì •ë„ ì˜ì—­ì„ ì°¨ì§€í•˜ì˜€ëŠëƒ?
- í•„í„° ì‚¬ì´ì¦ˆê°€ í´ìˆ˜ë¡ ë” ë„“ì€ ì˜ì—­ì„ ì°¸ê³ í•œë‹¤
- Suppose KxK conv. filters with stride 1, and a pooling of size PxP -> value of each unit in the pooling layer depends on an input patch of size: **(P+K-1)x(PxK-1)**

### VGGNet

<figure>
<img src="/assets/img/Screen Shot 2021-09-22 at 4.37.09 PM.png" width="400">
<figcaption>Fig 14. VGG16 and VGG19</figcaption>
</figure>

- ë” ê¹Šì–´ì§„ architecture (16 and 19 layers)
- ë” ë‹¨ìˆœí•´ì§„ architecture
    - LRN ì‚¬ìš© ì•ˆí•¨
    - 3x3 conv filtersê³¼ 2x2 max poolingë§Œ ì‚¬ìš©
- ë” ë‚˜ì€ performance and generalization
- Input
    - 224x224 RGB images (AlexNetê³¼ ë™ì¼)
    - í‰ê·  RGBê°’ì„ ë¹¼ì¤Œìœ¼ë¡œì¨ Normalization
- Key design choices
    - 3x3 conv filters with stride 1
    - 2x2 max pooling operations
- 3 fully-connected layers
- ReLU for non-linearity, No LRN

ğŸˆ ì™œ 3x3 conv layersë§Œ ì‚¬ìš©í–ˆëŠ”ê°€?
- í° receptive fieldë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë‹¤
- ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì— ë”°ë¼ì˜¤ëŠ” more non-linearities
- ë” ì ì€ parameter ìˆ˜

