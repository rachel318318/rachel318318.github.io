---
layout: post
title: 📔 Daily Report | Seg Comp Day 3
date: 2021-10-20 10:15 +0900
#modified: 2021-07-30 18:49 +0900
description: Seg Comp Day 3
tag:
  - Boostcamp AI
  - Daily Report
  - Semantic Segmentation Competition
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# 1. 피어 세션

💡 **공유 사항**
- 역할 분담?
    - Notion에 적어놓은 Task 많이 겹치지 않게 각자 알아서 하자
- mmseg도 활용하자
    - 깃헙에 성진님 브랜치 참고
- 나중에 implement 해볼 것
    - Stratified K-fold Ensemble
    - Stochastic Weight Averaging
    - Seed Ensemble
    - Convex Hull
    - Dense CRF
    - CropNonEmptyMaskIfExists Augmentation

# 2. 개인적으로 배운 것/리마인드

🌿 **Convolution vs. Transposed Convolution**

[https://www.reddit.com/r/MachineLearning/comments/4wbn81/are_deconvolution_layers_actually_needed/](https://www.reddit.com/r/MachineLearning/comments/4wbn81/are_deconvolution_layers_actually_needed/)

4강의 SegNet에서 Decoder 부분에 Transposed Convolution 대신 그냥 Convolution을 넣은 것을 보고 내가 생각하고 있는 각각의 정의가 맞는지 의심이 되었다. 내가 이해한 바로는 Encoder부분에는 Convolution을 사용해 feature를 뽑고 Transposed Convolution을 Decoder부분에 사용해 이미지의 크기를 키워주는 것이었는데 위에 reddit에 나온 설명을 보니 내 생각이 틀렸다는 생각이 들었다. 사실상 Transposed Convolution이 이미지의 크기를 키워주지 않고 Unpooling이 그 역할을 한다. 그리고 Transposed Convolution의 역할은 그 Unpooling으로 비워진 공간들을 채워주는 역할이라고 강의에서도 언급되었다. ~~강의를 잘 듣자~~ 위에서 답한 바로는 모델이 Underfitting일 때 TC가 도움이 되지만 Overfitting을 고칠 때는 오히려 도움이 안되고 (TC도 학습 가능한 파라미터를 가지기 때문) Unpooling+conv만으로도 충분히 Upsampling할 수 있다고 답했다.

🌿 **CNN output size 계산하기**

```
[(W−K+2P)/S]+1

W: input volume
K: kernel size
P: padding
S: stride
```

# 3. 앞으로 할 일

✅ ~~이번 주 강의 다 듣기~~\
▶️ 강의 노트 정리하기\
▶️ EDA하고 데이터 관찰기 쓰기\
▶️ **Baseline 코드 짜기 (.py으로 구성된 pytorch 프로젝트)**\
▶️ **솔루션들 벤치마킹하여 비교분석하기**\
▶️ SOTA 모델 구글링 하기