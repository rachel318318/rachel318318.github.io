---
layout: post
title: 📔 Daily Report | Day 32
date: 2021-09-14 10:15 +0900
#modified: 2021-07-30 18:49 +0900
description: Day 32
tag:
  - Boostcamp AI
  - Daily Report
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# 1. 수업 노트

asdfasdkfja;nv;aenvadseqerrbqefbqerb

# 2. 피어 세션

💡 **공유 사항**

**Q. AutoGrad를 한마디로 표현하면?**

- Chain Rule이 핵심이 될 것
- Tensor가 있으면 Forward가 함수를 거쳐서 나오게 되는데 어떤 과정을 거쳐서 이  값이 나오게 됐는지를 다 담고 있어서 backward가 가능하게 하는 것으로 이해한다.
- (Google 답변) Neural networks (NNs) are a collection of nested functions that are executed on some input data. These functions are defined by parameters (consisting of weights and biases
- 딥러닝에서 역전파하는데 사용되는 파이토치 엔진이며 그 과정에서는 chain rule이 적용이 된다. 
- API를 제공하기 전에는 하나하나 도함수를 찾았어야 했는데 API Loss가 계산 되기까지 지나왔떤 function이나 그런 것들을 담고 있기 때문에 별도로 한하나 구할필요 없이 한번에 해죽ㄴ런ㅁㅇ라ㅣㅓ ㅁ

- (정리해보자) Auto Grad는 deep learning에서 back-propagation을 하는데 사용되는 파이토치 엔진이다. Neural Net은 다양한 함수들이 합성된 합성함수로 미분시 Chain Rule을 적용해야한다. 
API를 제공하기 전에는 미분 과정을 하나하나 계산했다면 Autograd는 Forward시 지나오는 모든 function에 대한 정보를 담고 있기 때문에 이를 이용해 backprop을 자동으로 진행해준다. 

**관련자료**

[https://tutorials.pytorch.kr/beginner/blitz/autograd_tutorial.html](https://tutorials.pytorch.kr/beginner/blitz/autograd_tutorial.html)

[https://ko.d2l.ai/chapter_crashcourse/autograd.html](https://ko.d2l.ai/chapter_crashcourse/autograd.html)

💡 **TMI Session**

TMI 세션(김경민님) - 쉽고 빠른 LaTeX

# 3. 오늘 마치며...

