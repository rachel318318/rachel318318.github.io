---
layout: post
title: ğŸ’­ Image Class Comp | Training & Inference
date: 2021-08-26 07:44 +0900
#modified: 2021-07-30 18:49 +0900
description: ì´ë¯¸ì§€ ë¶„ë¥˜ ëŒ€íšŒë¥¼ ìœ„í•œ ëª¨ë¸ì„ ë§Œë“œëŠ” ê³¼ì •
tag:
  - Boostcamp AI
  - P-stage
  - Image Classification Competition
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# Key Concepts for Training

### Loss

<figure>
<img src="/assets/img/IMG_1270.jpg" alt="back propagation">
<figcaption>Fig 1. ì˜¤ë¥˜ ì—­ì „íŒŒ</figcaption>
</figure>

* Loss í•¨ìˆ˜ = Cost í•¨ìˆ˜ = Error í•¨ìˆ˜
* Lossë„ PyTorchì—ì„œ nn.Moduleì˜ Familyì´ë‹¤
* `loss.backward()`ê°€ ì‹¤í–‰ë˜ë©´ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ì˜ gradê°’ì´ ì—…ë°ì´íŠ¸ ëœë‹¤
    * `required_grad`ê°€ `True`ì¸ ê°’ë§Œ

* ì‹¬í™”ëœ Loss
    * Focal Loss: Class imbalance ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°, ë§ì¶˜ í™•ë¥ ì´ ë†’ì€ ClassëŠ” ì¡°ê¸ˆì˜ lossë¥¼, ë§ì¶˜ í™•ë¥ ì´ ë‚®ì€ classëŠ” lossë¥¼ í›¨ì”¬ ë†’ê²Œ ë¶€ì—¬
    * Label Smoothing Loss: Class target labelì„ onehot í‘œí˜„([1,0,0...])ë³´ë‹¤ëŠ” ì¡°ê¸ˆ softí•˜ê²Œ í‘œí˜„í•´ì„œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì„([0.9,0.25,0.25...])

### Optimizer

* ì–´ëŠ ë°©í–¥ìœ¼ë¡œ, ì–¼ë§ˆë‚˜ í¬ê²Œ íŒŒë¼ë¯¸í„° ê°’ì„ ì¡°ì •í• ì§€?
    * [Optimization]({% post_url /August2021/2021-08-10-Opt %}) í¬ìŠ¤íŠ¸ ì°¸ê³ 

* LR scheduler
    * Learning rateë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì ˆí•  ìˆ˜ ì—†ì„ê¹Œ?
    * `StepLR`: íŠ¹ì • Stepë§ˆë‹¤ LR ê°ì†Œ
    * `CosineAnnealingLR`: Cosine í•¨ìˆ˜ í˜•íƒœì²˜ëŸ¼ LRì„ ê¸‰ê²©íˆ ë³€ê²½
    * `ReduceLROnPlateau`: ë” ì´ìƒ ì„±ëŠ¥ í–¥ìƒì´ ì—†ì„ ë•Œ LR ê°ì†Œ

```py
# StepLR
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)

# CosineAnnealingLR
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)

# ReduceLROnPlateau
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, T_max=10, eta_min=0)
```

### Metric

í•™ìŠµëœ ëª¨ë¸ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§€í‘œê°€ í•„ìš”

**Classification**: Accuracy, F1-score, precision, recall, ROC & AUC

ğŸˆ ë°ì´í„° ìƒíƒœì— ë”°ë¼ ì ì ˆí•œ Metricì„ ì„ íƒí•´ì•¼í•œë‹¤\
ex) Class ë³„ë¡œ ì ì ˆíˆ ë¶„í¬ -> Accuracy, ì¢‹ì§€ ì•Šìœ¼ë©´ -> F1 score

**Regression**: MAE, MSE

**Ranking**: MRR, NDCG, MAP

# Training & Inference Process

### Training

<figure>
<img src="/assets/img/IMG_1271.jpg" alt="training code" width="450">
<figcaption>Fig 2. ëª¨ë¸ Training code ì˜ˆì‹œ</figcaption>
</figure>

* `model.train()`ìœ¼ë¡œ ì„ ì–¸ì„ ë¨¼ì € í•´ì¤€ë‹¤
* `optimizer.zero_grad()`
    * `optimizer`ëŠ” ë¯¸ë¦¬ ë”°ë¡œ ìƒì„±ì‹œí‚¨ë‹¤
    * ë§¤ epochë§ˆë‹¤ gradë¥¼ ì´ˆê¸°í™”ì‹œì¼œì¤€ë‹¤
* loss = criterion(outputs, labels)
    * ë³´í†µ `loss.py`ë¥¼ ë§Œë“¤ì–´ ê·¸ê³³ì— criterion classë¥¼ ì„ ì–¸í•´ì¤€ë‹¤
    * ë¬´ìŠ¨ loss functionì„ ì“¸ì§€ëŠ” ë§ˆìŒëŒ€ë¡œ
* `loss.backward`: ì—­ì „íŒŒë¡œ ëª¨ë¸ í•™ìŠµ
* `optimizer.step()`: `grad`ë¥¼ ì—…ë°ì´íŠ¸ ì‹œí‚¨ë‹¤

### Inference

<figure>
<img src="/assets/img/IMG_1272.jpg" alt="inference code" width="525">
<figcaption>Fig 3. Inference code ì˜ˆì‹œ</figcaption>
</figure>

* `model.eval()`ìœ¼ë¡œ í…ŒìŠ¤íŒ… ì‹œì‘ì„ ì„ ì–¸í•´ì¤€ë‹¤
* `with torch.no_grad()`: gradient ê³„ì‚°ì„ í•´ì œí•œë‹¤
* validation í™•ì¸: ì¶”ë¡  ê³¼ì •ì—ì„œ validation setìœ¼ë¡œ ë°”ê¿”ì£¼ê¸°ë§Œ í•˜ë©´ ëœë‹¤
* checkpoint: `torch.save(model, path)` or `torch.save(model.state_dict(), path)`

<figure>
<img src="/assets/img/IMG_1273.jpg" alt="training code">
<figcaption>Fig 4. torch.save ì˜ˆì‹œ</figcaption>
</figure>