---
layout: post
title: âœï¸ U-stage | ê²½ì‚¬í•˜ê°•ë²•
date: 2021-08-02 16:44 +0900
#modified: 2021-07-30 18:49 +0900
description: ë¨¸ì‹ ëŸ¬ë‹ ìˆ˜í•™ì˜ ê¸°ì´ˆê°€ ë˜ëŠ” ê°œë…ë“¤ì„ í›‘ì–´ë³´ëŠ” ì‹œê°„
tag:
  - Boostcamp AI
  - U-stage
  - AI math basics
# image: /cara-memperbarui-fork-repository/repo.png
usemathjax: true
---

# 1. ê²½ì‚¬í•˜ê°•ë²•(ìˆœí•œë§›)

### ë¯¸ë¶„

* ë³€ìˆ˜ì˜ ì›€ì§ì„ì— ë”°ë¥¸ í•¨ìˆ˜ê°’ì˜ ë³€í™”ë¥¼ ì¸¡ì €í•˜ê¸° ìœ„í•œ ë„êµ¬
* ìµœì í™”ì—ì„œ ì œì¼ ë§ì´ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•

$$f'(x)=\lim_{h\rightarrow0}\frac{f(x+h)-f(x)}{h}$$

* `sympy.diff`ë¡œ ê³„ì‚° ê°€ëŠ¥

```py
import sympy as sym
from sympy.abc import x

sym.diff(sym.poly(x**2 + 2*x + 3), x)
```

* ë¯¸ë¶„ì€ í•¨ìˆ˜ $$f$$ì˜ ì£¼ì–´ì§„ ì  $$(x,f(x))$$ì—ì„œì˜ ì ‘ì„ ì˜ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•¨
* ì–´ëŠ ë°©í–¥ìœ¼ë¡œ ì ì„ ì›€ì§ì—¬ì•¼ í•¨ìˆ˜ê°’ì´ ì¦ê°€í•˜ëŠ”ì§€/ê°ì†Œí•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆìŒ

<figure>
<img src="/assets/img/IMG_1181.jpg" alt="ì ‘ì„ ì˜ ê¸°ìš¸ê¸°">
<figcaption>Fig 1. (x,f(x))ì—ì„œì˜ ì ‘ì„ ì˜ ê¸°ìš¸ê¸°</figcaption>
</figure>

* ë¯¸ë¶„ê°’ì„ ë”í•˜ë©´ ê²½ì‚¬ìƒìŠ¹ë²•(gradient ascent), ë¯¸ë¶„ê°’ì„ ë¹¼ë©´ ê²½ì‚¬í•˜ê°•ë²•(gradient descent)
* ê° í•¨ìˆ˜ì˜ ê·¹ëŒ€ê°’ê³¼ ê·¹ì†Œê°’ì˜ ìœ„ì¹˜ë¥¼ êµ¬í•  ë•Œ ì‚¬ìš©í•¨

### ê²½ì‚¬í•˜ê°•ë²•: ì•Œê³ ë¦¬ì¦˜

```py
# gradient: ë¯¸ë¶„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
# init: ì‹œì‘ì , lr: í•™ìŠµë¥ , eps: ì•Œê³ ë¦¬ì¦˜ ì¢…ë£Œì¡°ê±´

var = init
grad = gradient(var)
while abs(grad) > eps:
  var = var - lr * grad
  grad = gradient(var)
```

ğŸˆ ì»´í“¨í„°ë¡œ ë¯¸ë¶„ì´ ì •í™•íˆ 0ì´ ë˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ `eps`ë³´ë‹¤ ì‘ì„ ë•Œ ì¢…ë£Œí•˜ëŠ” ì¡°ê±´ì´ í•„ìš”

ğŸˆ `lr`ì€ í•™ìŠµë¥ ë¡œì„œ ë¯¸ë¶„ì„ í†µí•´ ì—…ë°ì´íŠ¸í•˜ëŠ” ì†ë„ë¥¼ ì¡°ì ˆí•¨

### ë³€ìˆ˜ê°€ ë²¡í„°ì´ë©´?

* ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì¸ ê²½ìš° í¸ë¯¸ë¶„(partial differentiation)ì„ ì‚¬ìš©

$$\partial_{x_{i}}f(\textbf{x})=\lim_{h\rightarrow0}\frac{f(\textbf{x}+h\textbf{e}_{i})-f(\textbf{x})}{h}$$

* $$\textbf{e}_{i}$$ëŠ” $$i$$ë²ˆì§¸ ê°’ë§Œ 1ì´ê³  ë‚˜ë¨¸ì§€ëŠ” 0ì¸ ë‹¨ìœ„ë²¡í„°
* ê·¸ë ˆë””ì–¸íŠ¸(gradient) ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ ê²½ì‚¬í•˜ê°•/ê²½ì‚¬ìƒìŠ¹ë²•ì— ì ìš©

$$\nabla f=(\partial_{x_{1}}f,\partial_{x_{2}}f,\cdots,\partial_{x_{d}}f)$$

```py
import sympy as sym
from sympy.abc import x,y

sym.diff(sym.poly(x**2 + 2*x*y + 3) + sym.cos(x + 2*y), x)
# >> 2*x + 2*y - sin(x + 2*y)
```

<figure>
<img src="/assets/img/IMG_1182.jpg" alt="ê·¸ë ˆë””ì–¸íŠ¸ ë²¡í„°">
<figcaption>Fig 2. ê·¸ë ˆë””ì–¸íŠ¸ ë²¡í„°</figcaption>
</figure>

```py
# gradient: ë¯¸ë¶„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
# init: ì‹œì‘ì , lr: í•™ìŠµë¥ , eps: ì•Œê³ ë¦¬ì¦˜ ì¢…ë£Œì¡°ê±´

var = init
grad = gradient(var)
while norm(grad) > eps: #abs()ëŒ€ì‹  norm()ì¨ì„œ ì¢…ë£Œì¡°ê±´ ì„¤ì •
  var = var - lr * grad
  grad = gradient(var)
```

# 2. ê²½ì‚¬í•˜ê°•ë²•(ë§¤ìš´ë§›)

### ì„ í˜•íšŒê·€ë¶„ì„ ë³µìŠµ

* ì „ í¬ìŠ¤íŒ…ì— ë‚˜ì™”ë˜ <a href="/ë²¡í„°ì™€í–‰ë ¬/#ì‘ìš©2-ì„ í˜•íšŒê·€ë¶„ì„">ì„ í˜•íšŒê·€ë¶„ì„</a> ë¬¸ì œ ì°¸ê³ 
* ì—­í–‰ë ¬ ëŒ€ì‹  ê²½ì‚¬í•˜ê°•ë²•ìœ¼ë¡œ ì„ í˜•ëª¨ë¸ì„ ì°¾ì

### ì„ í˜•íšŒê·€ ê³„ìˆ˜ êµ¬í•˜ê¸°

$$\nabla_{\beta}\left\| y-\textbf{X}\beta \right\|_{2} = (\partial_{\beta_{1}}\left\| y-\textbf{X}\beta \right\|_{2},\dots,\partial_{\beta_{d}}\left\| y-\textbf{X}\beta \right\|_{2})$$

$$\partial_{\beta_{k}}\left\| y-\textbf{X}\beta \right\|_{2}=\partial_{\beta_{k}}\bigg\{\frac{1}{n}\sum_{i=1}^{n}\bigg(y_{i}-\sum_{j=1}^{d}X_{ij}\beta_{j}\bigg)^2\bigg\}^{1/2}$$

* ìµœì†Œí™”í•˜ëŠ” $$\beta$$ë¥¼ ì°¾ì•„ì•¼ í•¨
* ìœ„ ì‹ì„ ê³„ì‚°í•˜ë©´...

$$-\frac{\textbf{X}^{\top}(\textbf{y}-\textbf{X}\beta)}{n\|\textbf{y}-\textbf{X}\beta\|_{2}}$$

* $$\textbf{X}\beta$$ë¥¼ ê³„ìˆ˜ $$\beta$$ì— ëŒ€í•´ ë¯¸ë¶„í•œ ê²°ê³¼ì¸ $$\textbf{X}^{\top}$$ë§Œ ê³±í•´ì§„ ê²ƒ

ğŸ¤” ì–´ë–»ê²Œ ê³„ì‚°í•˜ëŠ”ì§€ ì•Œì•„ë‚¼ ê²ƒ...

<br/>

* ì œê³±í•˜ë©´ ì‹ì´ ë” ê°„ë‹¨í•´ì§„ë‹¤

$$\nabla_{\beta}\left\| y-\textbf{X}\beta \right\|_{2}^{2} = -\frac{2}{n}\textbf{X}^{\top}(\textbf{y}-\textbf{X}\beta)$$

* ëª©ì ì‹ì„ ìµœì†Œí™”í•˜ëŠ” $$\beta$$ë¥¼ êµ¬í•˜ëŠ” ê²½ì‚¬í•˜ê°•ë²• ì•Œê³ ë¦¬ì¦˜ì€...

$$\beta^{(t+1)}\leftarrow\beta^{t}-\lambda\nabla_{\beta}\|\textbf{y}-\textbf{X}\beta^{(t)}\|$$

* ë‘˜ì§¸ $$\lambda$$-termì— ëŒ€ì…í•˜ë©´ ë!

```py
# norm: L2-ë…¸ë¦„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
# lr: í•™ìŠµë¥ , T: í•™ìŠµíšŸìˆ˜

for t in range(T): # ì¢…ë£Œì¡°ê±´ì„ ì¼ì • í•™ìŠµíšŸìˆ˜ë¡œ ë³€ê²½
  error = y - X @ beta
  grad = - transpose(X) @ error
  beta = beta - lr * grad
```

ğŸˆ í•™ìŠµë¥ ê³¼ í•™ìŠµíšŸìˆ˜ê°€ ì¤‘ìš”í•´ì§„ë‹¤!

### ë¹„ì„ í˜•íšŒê·€ ë¬¸ì œ

* ëª©ì ì‹ì´ ë³¼ë¡í•˜ì§€ ì•Šì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê²½ì‚¬í•˜ê°•ë²•ì´ í•­ìƒ ìˆ˜ë ´ë³´ì¥x
* í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•(stochastic gradient descent):
  * ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  ë°ì´í„° í•œê°œ ë˜ëŠ” ì¼ë¶€ë¥¼ í™œìš©í•˜ì—¬ ì—…ë°ì´íŠ¸
* ë¯¸ë‹ˆë°°ì¹˜(batch)ëŠ” í™•ë¥ ì ìœ¼ë¡œ ì„ íƒí•˜ë¯€ë¡œ ëª©ì ì‹ ëª¨ì–‘ì´ ê³„ì† ë°”ë€œ

<figure>
<img src="/assets/img/IMG_1184.jpg" alt="í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•">
<figcaption>Fig 3. í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•ê³¼ ë‹¤ì–‘í•œ ëª©ì ì‹</figcaption>
</figure>

<figure>
<img src="/assets/img/IMG_1185.jpg" alt="í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• ì›ë¦¬">
<figcaption>Fig 4. í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• ì›ë¦¬</figcaption>
</figure>